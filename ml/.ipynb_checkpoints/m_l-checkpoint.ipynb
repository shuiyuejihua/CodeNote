{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习\n",
    "机器学习常用算法学习总结笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![机器学习必备技能](./ml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必备技能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 计算机科学基础知识和编程  \n",
    "\n",
    ">机器学习工程师务必掌握的计算机科学基础知识包括数据结构（堆栈、队列、多维数组、树、图表等）、算法（搜索、排序、优化、动态编程等）、计算能力和复杂度（P 与 NP、NP 完全问题、大 O 记法、近似算法等），以及计算机架构（内存、缓存、带宽、死锁、分布式处理等）。在编程时，你必须能够（相应地）应用、实施、调整或处理这些知识。练习题、编程竞赛和黑客马拉松是磨炼技能的好方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 概率与统计学  \n",
    "\n",
    ">概率的正式特性（条件概率、贝叶斯规则、似然、独立性等）和推出的技巧（贝叶斯网络、马尔可夫决策过程、隐藏式马可夫模型等）是很多机器学习算法的核心；我们可以通过多种方式来解决现实生活中的不确定性。与此领域关系紧密的是统计学，统计学提供了构建和验证通过观察的数据得出的模型所需的各种方法（均值、中位数、方差等）、分布（均匀分布、正态分布、二项分布、泊松分布等），以及分析方法（ANOVA、假设检验等）。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据建模和评估  \n",
    "\n",
    ">数据建模是估算给定数据集的底层结构的流程，旨在找到有用的规律（相互关系、集群、特征向量等），和/或预测之前未知实例的属性（分类、回归、异常检测等）。该估算过程的关键部分是继续评估给定模型有多好。根据手头上的任务，你需要选择相应的准确性/错误衡量方法（即分类模型的对数损失、回归模型的误差平方和等）。迭代学习算法经常会指定利用广义误差来调整模型（例如神经网络的反向传播），因此了解这些衡量措施很重要，即使仅仅应用标准算法也是如此。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 应用机器学习算法和库  \n",
    "\n",
    ">机器学习算法的标准实现可以广泛地通过库/包/API 获得（例如 scikit-learn、Theano、Spark MLlib、H2O、TensorFlow 等），但是有效的应用它们则需要选择合适的模型（决策树、近邻取样、神经网络、支持向量机、多个模型的组合，等） 、拟合数据的学习流程（线性回归、梯度下降、基因算法、装袋、推进和其他特定模型方法），以及了解超参数对学习有何影响。你还需要了解不同方法的相对优势和不足，以及会带来阻碍的各种陷阱（偏差和方差、过拟合和欠拟合、缺少数据、数据泄露等）。数据科学和机器学习挑战（例如​ Kaggle​ 上的挑战）是了解不同类型的问题和细微差别的很好的方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 软件工程和系统设计  \n",
    "\n",
    ">机器学习工程师的典型交付内容是软件。经常是纳入更大型的产品和服务生态系统的一个小组件。你需要了解这些不同组件是如何协同工作的，与它们通信（使用库调用、其他 API、数据查询等），并为你的组件构建其他组件将依赖的相应接口。可能有必要仔细设计系统，以避免瓶颈问题并使算法能够在数据量增多时灵活扩展。软件工程最佳做法（包括需求分析、系统设计、模块化、版本控制、测试、文档等）对生产力、合作性、质量和可维护性而言异常宝贵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 基本问题\n",
    "输入特征，若以单个单词作为输入，那么会因文本的长短不一，特征大小也不能统一"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词袋模型  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bag-of-words  \n",
    ">统计输入词出现的频率，构成向量。忽略一些stop word，比如：a, the, of。同时love、loves这种，单复数，统计主要词干，算一种。这种模型可以应用于其它文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特点：  \n",
    "1. 单词出现的顺序，对向量无影响  \n",
    "2. 倾向于长文本，比如同一个文本一次处理，和复制同一个文本内容放入一个文本中，词频翻倍，对词向量有影响  \n",
    "3. 不能处理复合词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn中的词袋模型  \n",
    ">CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit([list ok ])\n",
    "# 输出词频\n",
    "print(vect.vocabulary_.get('word'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stop words\n",
    ">low-information信息含量低的词语，比如：the，a，and，of  \n",
    "higly-frequent word 出现次数异常的多，和内容没多大关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    从中导入NTLK，使用stopword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import nltk\n",
    "nltk.download('stopwords')  # 下载词库\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('english')\n",
    "print(len(sw)) # 179\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stemmer\n",
    "> 词干提取，合并近义词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "st = SnowballStemmer('english')\n",
    "st.stem('word')\n",
    "# 显示word对应词干\n",
    "```\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TF-IDF\n",
    "> TF，由词频确定权重；IDF，由词出现在所有文本中的频率逆向加权，即，出现频率少的权重反而高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 贝叶斯\n",
    "naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GaussianNB高斯朴素贝叶斯\n",
    ">$$P(A|B) = \\frac{P(A,B)}{P(B)} = \\frac{P(B|A)P(A)}{P(B)}= \\frac{P(B|A)P(A)}{\\sum _{i=1}^{n}P(B|A_i)}$$\n",
    "P(A)为先验概率可根据大数定理，用样本频率来估计，  \n",
    "P(A|B)为后验概率，  \n",
    "P(B)用于归一化，与类标记无关,常数  \n",
    "P(B|A)，条件概率，似然概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.naive_bayes import GaussionNB\n",
    "clt = GaussionNB()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原理探讨\n",
    "> $$P(h|D) = \\frac{P(D|h)P(h)}{P(D)}$$\n",
    "h为假设，D为输入数据，如$(x_i,y_i)$：  \n",
    "P(h|D),给的数据集D，正确标记的概率；P(D|h),给定假设规则，根据输入数据，求得到对应标签的概率  \n",
    "P(h)：假设空间中h的先验概率；P(D)：数据集的先验概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 高斯分布，均值为$\\mu$，方差为$\\sigma^2$：$$f(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp{\\frac{-(x-\\mu)^2}{2\\sigma^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 贝叶斯决策论：基于概率、误判损失来选择最优标记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 期望损失 条件风险  \n",
    "$$R(c_i|x) = \\sum _{j=1}^N \\lambda_{ij}P(c_j|x)$$\n",
    "对每个样本x最小化，总体风险也将最小化.在每个样本上选择使条件风险最小的样本标记\n",
    "$$h(x) = argmin R(c|x)$$  \n",
    "误判损失：$\\lambda$ ,属于0/1损失函数，$$\\lambda_{ij} = \\begin{cases}0 &i = j\\\\1 & 其它\\end{cases}$$\n",
    "条件风险 $R(c|x) = 1-P(c|x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 则贝叶斯最优分类器为$$h(x) = argmax P(c|x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据贝叶斯公式：\n",
    "$$P(c|x) = \\frac{P(x|c)P(c)}{P(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "难在P(x|c)，指已知假设标记c，在所有数据上标记正确的概率，难以从有限数据上得出，所以假设条件独立\n",
    "$$P(x|c_k) = P(x1,x2,x3,x4...|c_k) = \\prod_{i=1}^nP(x_i|c_k)$$,其中c_k可以看似c，就看作当分类为一种的时候好理解点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于所有类别，P(x)相同，argmax P(c|x)，就等同于\n",
    "$$argmaxP(c)\\prod_{i=1}^nP(x_i|c_k)$$\n",
    "P(x)相同的原因，全概率公式：\n",
    "$$P(x) = \\sum_i^kP(x|c_i)P(c_i)=\\sum_i^kP(c_i)\\prod_{j=1}^nP(x_j|c_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，先验概率P(c),充足的独立同分布样本，$P(c)=\\frac{|D_c|}{D}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "离散属性：$P(x_i|c) = \\frac{|D_{c,x_i}|}{|D|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "连续属性，假定其属于高斯分布：$$P(x_i|c) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{c,i}} \\exp{\\frac{-(x-\\mu_{c,i})^2}{2\\sigma_{c,i}^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 拉普拉斯平滑  \n",
    "为避免属性之间有不同的组合，避免有的组合没有出现，但是算出的概率为0，被抹去，采用平滑处理。实际上假设属性、类别均分分布的  \n",
    "\n",
    "N,代表对应标签的类别数：$$P(c)=\\frac{|D_c|+1}{D+N}$$\n",
    "N_i,代表属性i的可能的取值数：$$P(x_i|c) = \\frac{|D_{c,x_i}|+1}{|D|+N_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">优点：在数据较少的情况下仍然有效，可以处理多类别问题。\n",
    "缺点：对于输入数据的准备方式较为敏感。\n",
    "适用数据类型：标称型数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">朴素贝叶斯：假设特征同等重要，特征之间独立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最优特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 信息增益"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息熵entropy：度量样本集合D纯合度，值越小，纯度越高。\n",
    "定义：$$Ent(D) = -\\sum_{i=1}^N{P_i}{\\log P_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益information gain，集合D,属性a，a有V个取值，$D^v$表示第v个取值的样本数，由于样本数不同，增加权重$\\frac{|D^v|}{|D|}$：\n",
    "$$Gain(D,a) = Ent(D) - \\sum_{v=1}^V\\frac{|D^v|}{|D|}Ent(D^v)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益越大，表示获得的提升越大，属性就选择使Gain(D,a)最大的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缺点：对可取值数目多的属性有所偏好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 信息增益比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益率gain ratio：信息增益和关于属性a的熵之比\n",
    "$$Gain_ratio(D,a) = \\frac{Gain(D,a)}{IV(a)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中IV(a):$$IV(a) = - \\sum_{v=1}^V\\frac{|D^v|}{|D|}log \\frac{|D^v|}{|D|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "样本数量越多，样本取值V越多，通常增益比降低，通常先计算增益，找出高于平均水平的，然后再从中选择增益比高的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 基尼系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基尼系数，gini index，从数据集D中随机抽取两个样本，类别标记不一致的概率，gini系数越小，纯度越高\n",
    "$$Gini(D) = 1-\\sum_{i=1}^{N}P^2_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "属性a的基尼系数为：$$Gini\\_index = \\sum_{i=1}^V\\frac{|D^v|}{|D|}Gini(D^v)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当属性a就只有1,0等2种取值，基尼系数就是唯一值；若有3种取值，基尼系数就由3小部分组成。然后再与其他属性值的基尼系数比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 剪枝防过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预剪枝：\n",
    "后剪枝："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 连续型数据、缺失数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "连续型数据：将属性排序，然后遍历n-1次，将数据划分2部分，找到使信息增益最大的划分点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缺失数据：  \n",
    "从属性中找出没缺失数据集D，计算$Ent(D))$，用未缺失数据占的比例为$\\rho$：\n",
    "$$Gain(D,a) = \\rho \\left (Ent(D) - \\sum_{v=1}^V\\frac{|D^v|}{|D|}Ent(D^v) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn.svm.SVC()参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c，值越大，边界越弯弯曲曲，分类正确变多，倾向于过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先分类，然后最大化，分类到数据间的距离，鲁棒性，泛化性能好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 间隔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性方程：$$W^Tx + b = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "样本正确分类，y取值1，-1；两个异类支持向量到超平面的距离之和：\n",
    "$$\\gamma = \\frac{2}{||w||}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大化间隔，等价于最小化$||w||^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
