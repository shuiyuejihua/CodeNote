{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习\n",
    "机器学习常用算法学习总结笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 基本问题\n",
    "输入特征，若以单个单词作为输入，那么会因文本的长短不一，特征大小也不能统一"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词袋模型  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bag-of-words  \n",
    ">统计输入词出现的频率，构成向量。忽略一些stop word，比如：a, the, of。同时love、loves这种，单复数，统计主要词干，算一种。这种模型可以应用于其它文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特点：  \n",
    "1. 单词出现的顺序，对向量无影响  \n",
    "2. 倾向于长文本，比如同一个文本一次处理，和复制同一个文本内容放入一个文本中，词频翻倍，对词向量有影响  \n",
    "3. 不能处理复合词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn中的词袋模型  \n",
    ">CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit([list ok ])\n",
    "# 输出词频\n",
    "print(vect.vocabulary_.get('word'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stop words\n",
    ">low-information信息含量低的词语，比如：the，a，and，of  \n",
    "higly-frequent word 出现次数异常的多，和内容没多大关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    从中导入NTLK，使用stopword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import nltk\n",
    "nltk.download('stopwords')  # 下载词库\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('english')\n",
    "print(len(sw)) # 179\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stemmer\n",
    "> 词干提取，合并近义词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "st = SnowballStemmer('english')\n",
    "st.stem('word')\n",
    "# 显示word对应词干\n",
    "```\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TF-IDF\n",
    "> TF，由词频确定权重；IDF，由词出现在所有文本中的频率逆向加权，即，出现频率少的权重反而高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 贝叶斯\n",
    "naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GaussianNB高斯朴素贝叶斯\n",
    ">$$P(A|B) = \\frac{P(A,B)}{P(B)} = \\frac{P(B|A)P(A)}{P(B)}= \\frac{P(B|A)P(A)}{\\sum _{i=1}^{n}P(B|A_i)}$$\n",
    "P(A)为先验概率可根据大数定理，用样本频率来估计，  \n",
    "P(A|B)为后验概率，  \n",
    "P(B)用于归一化，与类标记无关,常数  \n",
    "P(B|A)，条件概率，似然概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.naive_bayes import GaussionNB\n",
    "clt = GaussionNB()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原理探讨\n",
    "> $$P(h|D) = \\frac{P(D|h)P(h)}{P(D)}$$\n",
    "h为假设，D为输入数据，如$(x_i,y_i)$：  \n",
    "P(h|D),给的数据集D，正确标记的概率；P(D|h),给定假设规则，根据输入数据，求得到对应标签的概率  \n",
    "P(h)：假设空间中h的先验概率；P(D)：数据集的先验概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 高斯分布，均值为$\\mu$，方差为$\\sigma^2$：$$f(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp{\\frac{-(x-\\mu)^2}{2\\sigma^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 贝叶斯决策论：基于概率、误判损失来选择最优标记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 期望损失 条件风险  \n",
    "$$R(c_i|x) = \\sum _{j=1}^N \\lambda_{ij}P(c_j|x)$$\n",
    "对每个样本x最小化，总体风险也将最小化.在每个样本上选择使条件风险最小的样本标记\n",
    "$$h(x) = argmin R(c|x)$$  \n",
    "误判损失：$\\lambda$ ,属于0/1损失函数，$$\\lambda_{ij} = \\begin{cases}0 &i = j\\\\1 & 其它\\end{cases}$$\n",
    "条件风险 $R(c|x) = 1-P(c|x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 则贝叶斯最优分类器为$$h(x) = argmax P(c|x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据贝叶斯公式：\n",
    "$$P(c|x) = \\frac{P(x|c)P(c)}{P(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "难在P(x|c)，指已知假设标记c，在所有数据上标记正确的概率，难以从有限数据上得出，所以假设条件独立\n",
    "$$P(x|c_k) = P(x1,x2,x3,x4...|c_k) = \\prod_{i=1}^nP(x_i|c_k)$$,其中c_k可以看似c，就看作当分类为一种的时候好理解点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于所有类别，P(x)相同，argmax P(c|x)，就等同于\n",
    "$$argmaxP(c)\\prod_{i=1}^nP(x_i|c_k)$$\n",
    "P(x)相同的原因，全概率公式：\n",
    "$$P(x) = \\sum_i^kP(x|c_i)P(c_i)=\\sum_i^kP(c_i)\\prod_{j=1}^nP(x_j|c_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，先验概率P(c),充足的独立同分布样本，$P(c)=\\frac{|D_c|}{D}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "离散属性：$P(x_i|c) = \\frac{|D_{c,x_i}|}{|D|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "连续属性，假定其属于高斯分布：$$P(x_i|c) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{c,i}} \\exp{\\frac{-(x-\\mu_{c,i})^2}{2\\sigma_{c,i}^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 拉普拉斯平滑  \n",
    "为避免属性之间有不同的组合，避免有的组合没有出现，但是算出的概率为0，被抹去，采用平滑处理。实际上假设属性、类别均分分布的  \n",
    "\n",
    "N,代表对应标签的类别数：$$P(c)=\\frac{|D_c|+1}{D+N}$$\n",
    "N_i,代表属性i的可能的取值数：$$P(x_i|c) = \\frac{|D_{c,x_i}|+1}{|D|+N_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">优点：在数据较少的情况下仍然有效，可以处理多类别问题。\n",
    "缺点：对于输入数据的准备方式较为敏感。\n",
    "适用数据类型：标称型数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">朴素贝叶斯：假设特征同等重要，特征之间独立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最优特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 信息增益"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息熵entropy：度量样本集合D纯合度，值越小，纯度越高。\n",
    "定义：$$Ent(D) = -\\sum_{i=1}^N{P_i}{\\log P_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益information gain，集合D,属性a，a有V个取值，$D^v$表示第v个取值的样本数，由于样本数不同，增加权重$\\frac{|D^v|}{|D|}$：\n",
    "$$Gain(D,a) = Ent(D) - \\sum_{v=1}^V\\frac{|D^v|}{|D|}Ent(D^v)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益越大，表示获得的提升越大，属性就选择使Gain(D,a)最大的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缺点：对可取值数目多的属性有所偏好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 信息增益比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益率gain ratio：信息增益和关于属性a的熵之比\n",
    "$$Gain_ratio(D,a) = \\frac{Gain(D,a)}{IV(a)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中IV(a):$$IV(a) = - \\sum_{v=1}^V\\frac{|D^v|}{|D|}log \\frac{|D^v|}{|D|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "样本数量越多，样本取值V越多，通常增益比降低，通常先计算增益，找出高于平均水平的，然后再从中选择增益比高的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 基尼系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基尼系数，gini index，从数据集D中随机抽取两个样本，类别标记不一致的概率，gini系数越小，纯度越高\n",
    "$$Gini(D) = 1-\\sum_{i=1}^{N}P^2_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "属性a的基尼系数为：$$Gini\\_index = \\sum_{i=1}^V\\frac{|D^v|}{|D|}Gini(D^v)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
